{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a48f99dc-4dd1-4b92-83b2-b9d85f2e7750",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a890f21-b298-4a78-ac94-6e7412c17aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce95d9e9-ea0d-4fbb-96d8-01319c375413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-V4UBEI0:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1b69a9f4880>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f22ac112-4ec1-4e86-93e2-c3180eabeac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('olist_classified_public_dataset.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "996880d0-0f0b-43e5-9ffe-1b45d10a1f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|order_purchase_timestamp  |\n",
      "+--------------------------+\n",
      "|2017-08-30 11:41:01.000000|\n",
      "+--------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('order_purchase_timestamp').show(1,truncate= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7b41c239-5a45-47bd-91ef-40329b5ac5e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data '2017-08-30 11:41:01' does not match format 'YYYY-MM-DD H24:mi:ss.ssss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4708/1759160112.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimestampstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'YYYY-MM-DD H24:mi:ss.ssss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtimestr_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'2017-08-30 11:41:01'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4708/1759160112.py\u001b[0m in \u001b[0;36mtimestr_datetime\u001b[1;34m(timestampstr)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtimestr_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimestampstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimestampstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'YYYY-MM-DD H24:mi:ss.ssss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtimestr_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'2017-08-30 11:41:01'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\udemy_dgadraju_cca175\\udemyCca175Env\\lib\\_strptime.py\u001b[0m in \u001b[0;36m_strptime_datetime\u001b[1;34m(cls, data_string, format)\u001b[0m\n\u001b[0;32m    566\u001b[0m     \"\"\"Return a class cls instance based on the input string and the\n\u001b[0;32m    567\u001b[0m     format string.\"\"\"\n\u001b[1;32m--> 568\u001b[1;33m     \u001b[0mtt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfraction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgmtoff_fraction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_strptime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m     \u001b[0mtzname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgmtoff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfraction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\udemy_dgadraju_cca175\\udemyCca175Env\\lib\\_strptime.py\u001b[0m in \u001b[0;36m_strptime\u001b[1;34m(data_string, format)\u001b[0m\n\u001b[0;32m    347\u001b[0m     \u001b[0mfound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformat_regex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfound\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m         raise ValueError(\"time data %r does not match format %r\" %\n\u001b[0m\u001b[0;32m    350\u001b[0m                          (data_string, format))\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_string\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mfound\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: time data '2017-08-30 11:41:01' does not match format 'YYYY-MM-DD H24:mi:ss.ssss'"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "def timestr_datetime(timestampstr):\n",
    "    return datetime.datetime.strptime(timestampstr, 'YYYY-MM-DD H24:mi:ss.ssss')\n",
    "\n",
    "timestr_datetime('2017-08-30 11:41:01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "26bef8c7-63ec-42d0-a04c-1afdf06ac774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.timestr_datetime(timestampstr)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "udf_date_time = udf(timestr_datetime, TimestampType())\n",
    "\n",
    "spark.udf.register('udf_dt', timestr_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "150454b6-6a60-4ce8-bc7e-80bb6dff687f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def square_it(num):\n",
    "    return num*num\n",
    "\n",
    "square_it(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3a998dc-959f-4ed7-b6e1-2a5037c3ccb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'udf_date_time(order_purchase_timestamp)'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(udf_date_time('2017-08-30 11:41:01.000000'))\n",
    "udf_date_time(col('order_purchase_timestamp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "40d09eaf-792a-4c50-b399-09d82876f448",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"F:\\udemy_dgadraju_cca175\\udemyCca175Env\\lib\\site-packages\\pyspark\\serializers.py\", line 437, in dumps\n",
      "    return cloudpickle.dumps(obj, pickle_protocol)\n",
      "  File \"F:\\udemy_dgadraju_cca175\\udemyCca175Env\\lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle_fast.py\", line 72, in dumps\n",
      "    cp.dump(obj)\n",
      "  File \"F:\\udemy_dgadraju_cca175\\udemyCca175Env\\lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle_fast.py\", line 540, in dump\n",
      "    return Pickler.dump(self, obj)\n",
      "TypeError: cannot pickle '_thread.RLock' object\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Could not serialize object: TypeError: cannot pickle '_thread.RLock' object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mF:\\udemy_dgadraju_cca175\\udemyCca175Env\\lib\\site-packages\\pyspark\\serializers.py\u001b[0m in \u001b[0;36mdumps\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 437\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcloudpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPickleError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\udemy_dgadraju_cca175\\udemyCca175Env\\lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle_fast.py\u001b[0m in \u001b[0;36mdumps\u001b[1;34m(obj, protocol, buffer_callback)\u001b[0m\n\u001b[0;32m     71\u001b[0m             )\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[0mcp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\udemy_dgadraju_cca175\\udemyCca175Env\\lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle_fast.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    539\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 540\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    541\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot pickle '_thread.RLock' object",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4708/4134291138.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ts'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mudf_date_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'order_purchase_timestamp'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mF:\\udemy_dgadraju_cca175\\udemyCca175Env\\lib\\site-packages\\pyspark\\sql\\udf.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[1;33m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0massigned\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0massignments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\udemy_dgadraju_cca175\\udemyCca175Env\\lib\\site-packages\\pyspark\\sql\\udf.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *cols)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m         \u001b[0mjudf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_judf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m         \u001b[0msc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjudf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_seq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_to_java_column\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\udemy_dgadraju_cca175\\udemyCca175Env\\lib\\site-packages\\pyspark\\sql\\udf.py\u001b[0m in \u001b[0;36m_judf\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[1;31m# and should have a minimal performance impact.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_judf_placeholder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_judf_placeholder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_judf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_judf_placeholder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\udemy_dgadraju_cca175\\udemyCca175Env\\lib\\site-packages\\pyspark\\sql\\udf.py\u001b[0m in \u001b[0;36m_create_judf\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[0msc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparkContext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m         \u001b[0mwrapped_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_wrap_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturnType\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m         \u001b[0mjdt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparseDataType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturnType\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         judf = sc._jvm.org.apache.spark.sql.execution.python.UserDefinedPythonFunction(\n",
      "\u001b[1;32mF:\\udemy_dgadraju_cca175\\udemyCca175Env\\lib\\site-packages\\pyspark\\sql\\udf.py\u001b[0m in \u001b[0;36m_wrap_function\u001b[1;34m(sc, func, returnType)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_wrap_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturnType\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mcommand\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturnType\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mpickled_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbroadcast_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincludes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_prepare_for_python_RDD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     return sc._jvm.PythonFunction(bytearray(pickled_command), env, includes, sc.pythonExec,\n\u001b[0;32m     36\u001b[0m                                   sc.pythonVer, broadcast_vars, sc._javaAccumulator)\n",
      "\u001b[1;32mF:\\udemy_dgadraju_cca175\\udemyCca175Env\\lib\\site-packages\\pyspark\\rdd.py\u001b[0m in \u001b[0;36m_prepare_for_python_RDD\u001b[1;34m(sc, command)\u001b[0m\n\u001b[0;32m   2812\u001b[0m     \u001b[1;31m# the serialized command will be compressed by broadcast\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2813\u001b[0m     \u001b[0mser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCloudPickleSerializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2814\u001b[1;33m     \u001b[0mpickled_command\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2815\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpickled_command\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetBroadcastThreshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Default 1M\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2816\u001b[0m         \u001b[1;31m# The broadcast will have same life cycle as created PythonRDD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\udemy_dgadraju_cca175\\udemyCca175Env\\lib\\site-packages\\pyspark\\serializers.py\u001b[0m in \u001b[0;36mdumps\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    445\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Could not serialize object: %s: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0memsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m             \u001b[0mprint_exec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 447\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPicklingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPicklingError\u001b[0m: Could not serialize object: TypeError: cannot pickle '_thread.RLock' object"
     ]
    }
   ],
   "source": [
    "df1 = df.withColumn('ts', udf_date_time(col('order_purchase_timestamp')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f4ecd27-3288-40ef-b3ef-7d0a57bd7a76",
   "metadata": {},
   "outputs": [
    {
     "ename": "PythonException",
     "evalue": "\n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"F:\\opt\\spark-3.1.2-bin-hadoop3.2\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 604, in main\n  File \"F:\\opt\\spark-3.1.2-bin-hadoop3.2\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 596, in process\n  File \"F:\\opt\\spark-3.1.2-bin-hadoop3.2\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 211, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"F:\\opt\\spark-3.1.2-bin-hadoop3.2\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 132, in dump_stream\n    for obj in iterator:\n  File \"F:\\opt\\spark-3.1.2-bin-hadoop3.2\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 200, in _batched\n    for item in iterator:\n  File \"F:\\opt\\spark-3.1.2-bin-hadoop3.2\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 450, in mapper\n  File \"F:\\opt\\spark-3.1.2-bin-hadoop3.2\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 450, in <genexpr>\n  File \"F:\\opt\\spark-3.1.2-bin-hadoop3.2\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 85, in <lambda>\n  File \"F:\\opt\\spark-3.1.2-bin-hadoop3.2\\python\\lib\\pyspark.zip\\pyspark\\util.py\", line 73, in wrapper\n    return f(*args, **kwargs)\n  File \"C:\\Users\\parth\\AppData\\Local\\Temp/ipykernel_4708/1459416558.py\", line 3, in udf_date_time\n  File \"F:\\opt\\spark-3.1.2-bin-hadoop3.2\\python\\lib\\pyspark.zip\\pyspark\\sql\\functions.py\", line 1927, in to_timestamp\n    jc = sc._jvm.functions.to_timestamp(_to_java_column(col))\nAttributeError: 'NoneType' object has no attribute '_jvm'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPythonException\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4708/452072719.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mF:\\udemy_dgadraju_cca175\\udemyCca175Env\\lib\\site-packages\\pyspark\\sql\\dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    482\u001b[0m         \"\"\"\n\u001b[0;32m    483\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 484\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    485\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\udemy_dgadraju_cca175\\udemyCca175Env\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1304\u001b[1;33m         return_value = get_return_value(\n\u001b[0m\u001b[0;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0;32m   1306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\udemy_dgadraju_cca175\\udemyCca175Env\\lib\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    115\u001b[0m                 \u001b[1;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[1;31m# JVM exception message.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPythonException\u001b[0m: \n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"F:\\opt\\spark-3.1.2-bin-hadoop3.2\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 604, in main\n  File \"F:\\opt\\spark-3.1.2-bin-hadoop3.2\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 596, in process\n  File \"F:\\opt\\spark-3.1.2-bin-hadoop3.2\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 211, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"F:\\opt\\spark-3.1.2-bin-hadoop3.2\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 132, in dump_stream\n    for obj in iterator:\n  File \"F:\\opt\\spark-3.1.2-bin-hadoop3.2\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 200, in _batched\n    for item in iterator:\n  File \"F:\\opt\\spark-3.1.2-bin-hadoop3.2\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 450, in mapper\n  File \"F:\\opt\\spark-3.1.2-bin-hadoop3.2\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 450, in <genexpr>\n  File \"F:\\opt\\spark-3.1.2-bin-hadoop3.2\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 85, in <lambda>\n  File \"F:\\opt\\spark-3.1.2-bin-hadoop3.2\\python\\lib\\pyspark.zip\\pyspark\\util.py\", line 73, in wrapper\n    return f(*args, **kwargs)\n  File \"C:\\Users\\parth\\AppData\\Local\\Temp/ipykernel_4708/1459416558.py\", line 3, in udf_date_time\n  File \"F:\\opt\\spark-3.1.2-bin-hadoop3.2\\python\\lib\\pyspark.zip\\pyspark\\sql\\functions.py\", line 1927, in to_timestamp\n    jc = sc._jvm.functions.to_timestamp(_to_java_column(col))\nAttributeError: 'NoneType' object has no attribute '_jvm'\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b8c53d0-3d87-4537-8253-e3097f2c7ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+------------+--------------------+-------------------+---------------+-----------------+------------------------+--------------------+-----------------------------+-----------------------------+--------------------+--------------+------------------------+---------------------+-------------------+--------------------------+------------------+------------+--------------------+----------------------+--------------------+-----------------------+---------------------+-------------+-----------------+------------+---------------------+----------------------+--------------------+-----------------+---------------+-------------------+--------------------+---------------+\n",
      "|_c0| id|order_status|order_products_value|order_freight_value|order_items_qty|order_sellers_qty|order_purchase_timestamp|    order_aproved_at|order_estimated_delivery_date|order_delivered_customer_date|       customer_city|customer_state|customer_zip_code_prefix|product_category_name|product_name_lenght|product_description_lenght|product_photos_qty|review_score|review_comment_title|review_comment_message|review_creation_date|review_answer_timestamp|votes_before_estimate|votes_delayed|votes_low_quality|votes_return|votes_not_as_anounced|votes_partial_delivery|votes_other_delivery|votes_other_order|votes_satisfied|most_voted_subclass|    most_voted_class|      greetings|\n",
      "+---+---+------------+--------------------+-------------------+---------------+-----------------+------------------------+--------------------+-----------------------------+-----------------------------+--------------------+--------------+------------------------+---------------------+-------------------+--------------------------+------------------+------------+--------------------+----------------------+--------------------+-----------------------+---------------------+-------------+-----------------+------------+---------------------+----------------------+--------------------+-----------------+---------------+-------------------+--------------------+---------------+\n",
      "|  0|  1|   delivered|               89.99|              14.38|              1|                1|    2017-08-30 11:41:...|2017-08-30 11:55:...|         2017-09-21 00:00:...|         2017-09-08 20:35:...|      Belo Horizonte|            MG|                     308|         beleza_saude|                 59|                       492|                 3|           5|                null|            tudo certo|2017-09-09 00:00:...|   2017-09-10 03:27:...|                    0|            0|                0|           0|                    0|                     0|                   0|                0|              3|         satisfeito|satisfeito_com_pe...|Hello delivered|\n",
      "|  1|  2|   delivered|                69.0|              15.23|              1|                1|    2017-09-26 09:13:...|2017-09-26 09:28:...|         2017-10-24 00:00:...|         2017-09-29 21:13:...|     Pocos de Caldas|            MG|                     377|           brinquedos|                 50|                       679|                 4|           5|                null|  o produto chegou ...|2017-09-30 00:00:...|   2017-10-03 05:34:...|                    3|            0|                0|           0|                    0|                     0|                   0|                0|              0|        antes_prazo|satisfeito_com_pe...|Hello delivered|\n",
      "|  2|  3|   delivered|                99.8|              15.86|              2|                4|    2018-01-15 15:50:...|2018-01-17 07:29:...|         2018-02-05 00:00:...|         2018-01-23 17:51:...| Sao Jose dos Campos|            SP|                     122|   ferramentas_jardim|                 59|                       341|                 2|           1|                null|  foi adquirido 6 i...|2018-01-24 00:00:...|   2018-02-02 17:42:...|                    0|            0|                0|           0|                    0|                     3|                   0|                0|              0|    entrega_parcial|problemas_de_entrega|Hello delivered|\n",
      "|  3|  4|   delivered|                87.0|              12.74|              1|                1|    2018-02-04 11:16:...|2018-02-06 05:31:...|         2018-03-13 00:00:...|         2018-02-20 19:38:...|      Ribeirao Preto|            SP|                     140| informatica_acess...|                 45|                       411|                 1|           4|                null|  achei a entrega u...|2018-02-21 00:00:...|   2018-02-22 02:09:...|                    0|            3|                0|           0|                    0|                     0|                   0|                0|              0|           atrasado|problemas_de_entrega|Hello delivered|\n",
      "|  4|  5|   delivered|                99.9|              17.95|              1|                2|    2017-12-07 11:58:...|2017-12-08 02:36:...|         2018-01-03 00:00:...|         2017-12-19 22:33:...|      RIO DE JANEIRO|            RJ|                     205|      cama_mesa_banho|                 60|                       189|                 1|           3|                null|  comprei 02 jogos ...|2017-12-20 00:00:...|   2017-12-23 04:17:...|                    0|            0|                0|           0|                    0|                     3|                   0|                0|              0|    entrega_parcial|problemas_de_entrega|Hello delivered|\n",
      "|  5|  6|   delivered|               39.99|               0.15|              1|                6|    2017-11-02 11:33:...|2017-11-04 08:05:...|         2017-11-23 00:00:...|         2017-11-09 19:09:...|           Sao Paulo|            SP|                      20| fashion_bolsas_e_...|                 53|                       386|                 1|           5|                null|  apesar de ser da ...|2017-11-10 00:00:...|   2017-11-13 22:28:...|                    0|            0|                0|           0|                    0|                     1|                   1|                1|              0|               null|                null|Hello delivered|\n",
      "|  6|  7|   delivered|               229.9|              30.01|              1|                1|    2017-11-26 23:58:...|2017-11-27 00:18:...|         2017-12-28 00:00:...|         2017-12-19 14:13:...|            Floresta|            PE|                     564|     moveis_decoracao|                 54|                      1120|                 8|           2|                null|  não gostei de ter...|2017-12-20 00:00:...|   2017-12-21 12:44:...|                    0|            0|                0|           0|                    0|                     0|                   3|                0|              0|      outro_entrega|problemas_de_entrega|Hello delivered|\n",
      "|  7|  8|   delivered|               164.9|               8.41|              1|                1|    2017-12-08 21:13:...|2017-12-08 21:32:...|         2017-12-27 00:00:...|         2017-12-26 16:09:...|           SAO PAULO|            SP|                      83|   relogios_presentes|                 50|                       448|                 1|           5|                null|  recomendo essa lo...|2017-12-27 00:00:...|   2017-12-27 23:23:...|                    2|            0|                0|           0|                    0|                     0|                   0|                0|              1|        antes_prazo|satisfeito_com_pe...|Hello delivered|\n",
      "|  8|  9|   delivered|                89.9|              40.62|              1|                1|    2017-07-04 16:12:...|2017-07-04 16:24:...|         2017-07-24 00:00:...|         2017-07-10 16:35:...|           Juquitiba|            SP|                      69|     malas_acessorios|                 47|                       482|                 2|           3|                null|  produto entregue ...|2017-07-11 00:00:...|   2017-07-14 14:42:...|                    1|            0|                0|           0|                    0|                     0|                   0|                0|              2|         satisfeito|satisfeito_com_pe...|Hello delivered|\n",
      "|  9| 10|   delivered|                99.9|              19.94|              1|                1|    2017-11-29 04:25:...|2017-12-01 11:32:...|         2017-12-29 00:00:...|         2017-12-18 15:22:...|            Salvador|            BA|                     403|      cama_mesa_banho|                 60|                       189|                 1|           4|                null|        adorei nota 10|2017-12-19 00:00:...|   2017-12-21 20:10:...|                    0|            0|                0|           0|                    0|                     0|                   0|                0|              3|         satisfeito|satisfeito_com_pe...|Hello delivered|\n",
      "| 10| 11|   delivered|               99.99|              14.43|              1|                1|    2018-02-13 17:15:...|2018-02-14 17:10:...|         2018-03-23 00:00:...|         2018-02-26 18:57:...|           Sao Paulo|            SP|                      33| informatica_acess...|                 58|                      1390|                 2|           5|                null|  foi entregue prod...|2018-02-27 00:00:...|   2018-02-28 02:48:...|                    0|            0|                0|           2|                    1|                     0|                   0|                0|              0|          devolucao|problemas_de_qual...|Hello delivered|\n",
      "| 11| 12|   delivered|                65.9|               17.2|              1|                1|    2017-04-19 13:45:...|2017-04-21 05:22:...|         2017-05-25 00:00:...|         2017-05-09 09:03:...|         Nova Iguacu|            RJ|                     260|      cama_mesa_banho|                 46|                       104|                 1|           5|                null|  o produto atendeu...|2017-05-10 00:00:...|   2017-05-13 16:55:...|                    0|            0|                0|           0|                    0|                     0|                   0|                0|              3|         satisfeito|satisfeito_com_pe...|Hello delivered|\n",
      "| 12| 13|   delivered|               137.4|              12.17|              1|                1|    2017-09-13 23:19:...|2017-09-13 23:30:...|         2017-09-25 00:00:...|         2017-09-15 19:51:...|           Sao Paulo|            SP|                      43| livros_interesse_...|                 46|                      3833|                 7|           1|                null|  vieram apenas 6 l...|2017-09-16 00:00:...|   2017-09-19 04:39:...|                    0|            0|                0|           0|                    1|                     2|                   0|                0|              0|    entrega_parcial|problemas_de_entrega|Hello delivered|\n",
      "| 13| 14|     shipped|               69.99|              15.24|              1|                1|    2018-01-31 21:35:...|2018-02-01 03:12:...|         2018-03-05 00:00:...|                         null|           Fortaleza|            CE|                     608|       consoles_games|                 39|                      2751|                 6|           1|                null|  ainda não recebi ...|2018-03-08 00:00:...|   2018-03-11 11:37:...|                    0|            3|                0|           0|                    0|                     0|                   0|                0|              0|           atrasado|problemas_de_entrega|  Hello shipped|\n",
      "| 14| 15|   delivered|                59.9|              12.81|              1|                4|    2017-06-27 14:18:...|2017-06-28 02:45:...|         2017-07-19 00:00:...|         2017-06-29 13:30:...|           Sao Paulo|            SP|                      14| utilidades_domest...|                 41|                       799|                 1|           4|                null|  foram adquiridos ...|2017-06-30 00:00:...|   2017-07-01 15:16:...|                    0|            0|                0|           0|                    0|                     3|                   0|                0|              0|    entrega_parcial|problemas_de_entrega|Hello delivered|\n",
      "| 15| 16|   delivered|                66.0|              25.74|              1|                1|    2017-10-10 23:17:...|2017-10-10 23:28:...|         2017-11-10 00:00:...|         2017-10-30 19:52:...|Vitoria de Santo ...|            PE|                     556|     moveis_decoracao|                 45|                       494|                 1|           5|                null|  entregue corretam...|2017-10-31 00:00:...|   2017-11-03 00:28:...|                    0|            0|                0|           0|                    0|                     0|                   0|                0|              3|         satisfeito|satisfeito_com_pe...|Hello delivered|\n",
      "| 16| 17|   delivered|                23.7|               8.82|              1|                1|    2018-03-15 12:11:...|2018-03-16 03:50:...|         2018-04-11 00:00:...|         2018-03-21 23:12:...| Sao Jose dos Campos|            SP|                     122|     eletrodomesticos|                 31|                       115|                 1|           5|                null|  eu recomendo aten...|2018-03-22 00:00:...|   2018-03-24 23:55:...|                    0|            0|                0|           0|                    0|                     0|                   0|                0|              3|         satisfeito|satisfeito_com_pe...|Hello delivered|\n",
      "| 17| 18|   delivered|               59.99|               8.72|              1|                1|    2018-02-28 15:19:...|2018-02-28 15:30:...|         2018-03-13 00:00:...|         2018-03-05 17:17:...|           Sao Paulo|            SP|                      14|           brinquedos|                 29|                       291|                 3|           5|                null|  recebi a mercador...|2018-03-06 00:00:...|   2018-03-07 14:37:...|                    3|            0|                0|           0|                    0|                     0|                   0|                0|              0|        antes_prazo|satisfeito_com_pe...|Hello delivered|\n",
      "| 18| 19|   delivered|                97.9|              11.89|              1|                1|    2017-12-25 12:05:...|2017-12-27 04:07:...|         2018-01-15 00:00:...|         2018-01-10 16:44:...|        Praia Grande|            SP|                     117|          eletronicos|                 60|                       390|                 7|           5|                null|  tudo dentro do es...|2018-01-11 00:00:...|   2018-01-12 21:33:...|                    3|            0|                0|           0|                    0|                     0|                   0|                0|              0|        antes_prazo|satisfeito_com_pe...|Hello delivered|\n",
      "| 19| 20|   delivered|              195.99|              34.14|              1|                4|    2017-08-20 19:40:...|2017-08-21 20:25:...|         2017-09-15 00:00:...|         2017-08-28 19:37:...|          Vila Velha|            ES|                     291|      cama_mesa_banho|                 46|                       471|                 1|           2|                null|  eu so recebi 01 k...|2017-08-29 00:00:...|   2017-09-01 04:41:...|                    0|            0|                0|           0|                    0|                     3|                   0|                0|              0|    entrega_parcial|problemas_de_entrega|Hello delivered|\n",
      "+---+---+------------+--------------------+-------------------+---------------+-----------------+------------------------+--------------------+-----------------------------+-----------------------------+--------------------+--------------+------------------------+---------------------+-------------------+--------------------------+------------------+------------+--------------------+----------------------+--------------------+-----------------------+---------------------+-------------+-----------------+------------+---------------------+----------------------+--------------------+-----------------+---------------+-------------------+--------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@udf(returnType=StringType())\n",
    "def say_hello(name):\n",
    "     return f\"Hello {name}\"\n",
    "# This doesn't work anymore\n",
    "#assert say_hello(\"Summer\") == \"Hello Summer\"\n",
    "df.withColumn(\"greetings\", say_hello(col(\"order_status\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6f8960-49c9-4cec-af36-d5b8a2e9420e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
